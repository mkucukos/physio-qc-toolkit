{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# ðŸ“¦ Core Python Libraries\n",
    "# ==============================\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ==============================\n",
    "# ðŸ§® Scientific & Data Libraries\n",
    "# ==============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt, welch\n",
    "\n",
    "# ==============================\n",
    "# ðŸ«€ Signal Processing & EDF I/O\n",
    "# ==============================\n",
    "import pyedflib\n",
    "from util.read_edf import read_edf_metadata, read_edf_to_dataframes\n",
    "\n",
    "# ==============================\n",
    "# ðŸ§  Quality Control Modules\n",
    "# ==============================\n",
    "from quality.ecg_quality import run_ecg_qc\n",
    "from quality.flow_quality import run_flow_qc\n",
    "from quality.technical_quality import run_clipping_qc\n",
    "\n",
    "# ==============================\n",
    "# ðŸ“Š Visualization\n",
    "# ==============================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ THE METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_metadata_df = read_edf_metadata(\"ABC100110013333PSG06.edf\")\n",
    "edf_metadata_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ THE CHANNEL INTO DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_dataframes = read_edf_to_dataframes(\"ABC100110013333PSG06.edf\")\n",
    "# The EDF file contains 23 signals (EOG, EEG, EMG, ECG, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_ii_df = channel_dataframes['ECG II']\n",
    "ecg_ii_df = ecg_ii_df.rename(columns={'Relative Time (s)': 'Time (s)', 'ECG II_Data': 'ECG II'})\n",
    "ecg_ii_df[\"Absolute Time\"] = pd.to_datetime(ecg_ii_df[\"Absolute Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_dataframes[\"ECG IIHF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK THE TECHNICAL QUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_epoch, per_metric, overall = run_clipping_qc(\n",
    "    channel_name=\"Technical (RI_Diag_Device Alice_5)\",\n",
    "    channel_dataframes=channel_dataframes,\n",
    "    fs=200,\n",
    "    epoch_len=30,\n",
    "    rail_min=0.0,\n",
    "    rail_max=65535.0,\n",
    "    near_pct=0.01,\n",
    "    plot=True,\n",
    "    json_path=False\n",
    ")\n",
    "print(overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK THE ECG QUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import butter, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Parameters ---\n",
    "fs = 250  # sampling frequency\n",
    "epoch_len_sec = 30\n",
    "signal = ecg_ii_df[\"ECG II\"].values.astype(float)\n",
    "\n",
    "# --- Helper: Flatline detection ---\n",
    "def flatline_ratio(sig, eps=1e-6):\n",
    "    if len(sig) < 2:\n",
    "        return 1.0\n",
    "    diffs = np.abs(np.diff(sig))\n",
    "    return float(np.mean(diffs < eps))\n",
    "\n",
    "# --- Create augmented signal: add inverted first half to the end ---\n",
    "half_len = len(signal) // 2\n",
    "signal_aug = np.concatenate([signal, -1 * signal[:half_len]])\n",
    "\n",
    "# --- Filter design ---\n",
    "b, a = butter(4, (0.25, 25), 'bandpass', fs=fs)\n",
    "epoch_len = fs * epoch_len_sec\n",
    "n_epochs = len(signal_aug) // epoch_len\n",
    "\n",
    "records = []\n",
    "filtered_full = np.zeros_like(signal_aug)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    start = i * epoch_len\n",
    "    end = start + epoch_len\n",
    "    segment = signal_aug[start:end]\n",
    "\n",
    "    try:\n",
    "        ecg_filt = filtfilt(b, a, segment)\n",
    "        ecg_clean = nk.ecg_clean(ecg_filt, sampling_rate=fs)\n",
    "    except Exception:\n",
    "        ecg_clean = segment\n",
    "\n",
    "    filtered_full[start:end] = ecg_clean\n",
    "\n",
    "    # --- Flatline check ---\n",
    "    flat_ratio = flatline_ratio(ecg_clean)\n",
    "    is_flat = flat_ratio > 0.95  # if >95% points unchanged â†’ flatline\n",
    "\n",
    "    if is_flat or np.std(ecg_clean) == 0:\n",
    "        inv_ratio = 0  # mark as normal (non-inverted)\n",
    "        was_inverted = False\n",
    "    else:\n",
    "        # Inversion metric\n",
    "        r = np.corrcoef(ecg_clean, np.abs(ecg_clean))[0, 1]\n",
    "        inv_ratio = (1 - r) / 2\n",
    "        try:\n",
    "            _, was_inverted = nk.ecg_invert(ecg_clean, sampling_rate=fs, show=False)\n",
    "        except Exception:\n",
    "            was_inverted = np.nan\n",
    "\n",
    "    records.append({\n",
    "        \"epoch\": i,\n",
    "        \"start_time_s\": start / fs,\n",
    "        \"end_time_s\": end / fs,\n",
    "        \"flatline_ratio\": flat_ratio,\n",
    "        \"inversion_ratio\": inv_ratio,\n",
    "        \"was_inverted\": was_inverted,\n",
    "        \"is_flatline\": is_flat\n",
    "    })\n",
    "\n",
    "df_epochs = pd.DataFrame(records)\n",
    "df_epochs[\"high_inversion\"] = (df_epochs[\"inversion_ratio\"] > 0.5) & (~df_epochs[\"is_flatline\"])\n",
    "\n",
    "# --- Create time axis ---\n",
    "t_all = np.arange(len(filtered_full)) / fs\n",
    "\n",
    "# --- Matplotlib Figure ---\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(t_all, filtered_full, color='black', linewidth=0.8, label=\"Filtered ECG\")\n",
    "\n",
    "# Highlight epochs: red = inverted, green = normal or flatline\n",
    "for _, row in df_epochs.iterrows():\n",
    "    color = \"red\" if row[\"high_inversion\"] else \"green\"\n",
    "    plt.axvspan(row[\"start_time_s\"], row[\"end_time_s\"], color=color, alpha=0.18)\n",
    "\n",
    "# --- Layout customization ---\n",
    "plt.title(\"ECG Inversion Detection â€” Flatline Treated as Normal\", fontsize=14)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude (a.u.)\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_epoch, per_metric_json, overall_json = run_ecg_qc(\n",
    "    \"ECG II\",\n",
    "    channel_dataframes=channel_dataframes,   # your dict with ECG data\n",
    "    fs=200,\n",
    "    epoch_len=30,\n",
    "    thresholds={\n",
    "        \"clipping_max\": 0.50,\n",
    "        \"flatline_max\": 0.50,\n",
    "        \"missing_max\":  0.50,\n",
    "        \"baseline_max\": 0.15,\n",
    "        \"hr_min\": 25.0,\n",
    "        \"hr_max\": 220.0,\n",
    "        \"snr_min\": 5.0,\n",
    "    },\n",
    "    json_path=\"qc_summary.json\",\n",
    "    plot=\"per-metric\"\n",
    ")\n",
    "\n",
    "print(overall_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Save per_epoch to a separate JSON file ---\n",
    "with open(\"per_epoch_ecg.json\", \"w\") as f:\n",
    "    json.dump(per_epoch, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved per-epoch QC details to per_epoch.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# ---------------- Parameters ----------------\n",
    "json_path = \"per_epoch_ecg.json\"   # path to your saved file\n",
    "time_format = \"%Y-%m-%d %H:%M:%S\"  # adjust if timestamps differ\n",
    "\n",
    "# ---------------- Load JSON ----------------\n",
    "with open(json_path, \"r\") as f:\n",
    "    per_epoch = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(per_epoch)\n",
    "print(f\"âœ… Loaded {len(df)} epochs from {json_path}\")\n",
    "\n",
    "# ---------------- Convert Times ----------------\n",
    "df[\"Start_Time\"] = pd.to_datetime(df[\"Start_Time\"], errors=\"coerce\")\n",
    "df[\"End_Time\"] = pd.to_datetime(df[\"End_Time\"], errors=\"coerce\")\n",
    "df[\"Mid_Time\"] = df[\"Start_Time\"] + (df[\"End_Time\"] - df[\"Start_Time\"]) / 2\n",
    "\n",
    "# ---------------- Available Metrics ----------------\n",
    "metric_flags = {\n",
    "    \"Clipping_Ratio\": \"Bad_Clip\",\n",
    "    \"Flatline_Ratio\": \"Bad_Flatline\",\n",
    "    \"Missing_Ratio\": \"Bad_Missing\",\n",
    "    \"Baseline_Wander_Ratio\": \"Bad_Baseline\",\n",
    "    \"HR_Mean\": \"Bad_HR\",\n",
    "    \"SNR_dB\": \"Bad_SNR\",\n",
    "}\n",
    "\n",
    "available_metrics = [m for m in metric_flags if m in df.columns]\n",
    "print(f\"ðŸ“Š Available metrics for plotting: {available_metrics}\")\n",
    "\n",
    "# ---------------- Per-Metric Plots ----------------\n",
    "for metric in available_metrics:\n",
    "    bad_flag = metric_flags[metric]\n",
    "    if bad_flag not in df.columns:\n",
    "        continue\n",
    "\n",
    "    # Time vs Metric value\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(df[\"Mid_Time\"], df[metric], \"k.-\", label=metric)\n",
    "\n",
    "    # Shade good/bad epochs\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[\"Start_Time\"]) or pd.isna(row[\"End_Time\"]):\n",
    "            continue\n",
    "        color = \"red\" if row[bad_flag] else \"green\"\n",
    "        ax.axvspan(row[\"Start_Time\"], row[\"End_Time\"], color=color, alpha=0.15)\n",
    "\n",
    "    ax.set_title(f\"{metric} â€” QC Highlight (Green = Good, Red = Bad)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Finished generating per-metric QC plots.\")\n",
    "\n",
    "\n",
    "# ---------------- Raw ECG Waveform Reconstruction ----------------\n",
    "if \"Raw_Data\" in df.columns:\n",
    "    print(\"ðŸ«€ Plotting continuous raw ECG waveform with QC shading...\")\n",
    "\n",
    "    # Combine all raw samples\n",
    "    raw_all = np.concatenate([\n",
    "        np.array(x, dtype=float) if isinstance(x, list) else np.array([])\n",
    "        for x in df[\"Raw_Data\"]\n",
    "    ])\n",
    "\n",
    "    # Approximate sampling rate\n",
    "    total_duration = (df[\"End_Time\"].iloc[-1] - df[\"Start_Time\"].iloc[0]).total_seconds()\n",
    "    fs = len(raw_all) / total_duration if total_duration > 0 else 200\n",
    "\n",
    "    # Generate continuous timestamp array\n",
    "    t_start = df[\"Start_Time\"].iloc[0]\n",
    "    t_all = pd.date_range(start=t_start, periods=len(raw_all), freq=pd.Timedelta(seconds=1/fs))\n",
    "\n",
    "    print(f\"Reconstructed ECG: {len(raw_all)} samples, fs â‰ˆ {fs:.2f} Hz\")\n",
    "\n",
    "    # Plot continuous ECG with shaded epochs\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.plot(t_all, raw_all, lw=0.7, color=\"black\")\n",
    "\n",
    "    # Shade epochs based on QC\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[\"Start_Time\"]) or pd.isna(row[\"End_Time\"]):\n",
    "            continue\n",
    "        color = \"red\" if row[\"Bad_Epoch\"] else \"green\"\n",
    "        ax.axvspan(row[\"Start_Time\"], row[\"End_Time\"], color=color, alpha=0.18)\n",
    "\n",
    "    ax.set_title(\"ECG Raw Signal â€” QC Overlay (Green = Good, Red = Bad)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Amplitude (a.u.)\")\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ No 'Raw_Data' field found in JSON â€” skipping raw signal plot.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ FLOW Thermistor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airflow_thermistor_df = channel_dataframes['Flow Patient (Thermistor)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airflow_thermistor_df = channel_dataframes['Flow Patient (Thermistor)']\n",
    "airflow_thermistor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuroKit2 for respiration rate (pip install neurokit2)\n",
    "try:\n",
    "    import neurokit2 as nk\n",
    "    HAVE_NK = True\n",
    "except Exception:\n",
    "    HAVE_NK = False\n",
    "\n",
    "# ---------------- Parameters ----------------\n",
    "fs = 100                   # Hz\n",
    "epoch_len = 30             # seconds (non-overlapping)\n",
    "low_bpm_warn = 4.0         # draw a line at 4 BPM\n",
    "bp_lo, bp_hi = 0.10, 1.00  # Hz bandpass for airflow (resp band)\n",
    "\n",
    "# ---------------- Prepare Data ----------------\n",
    "airflow_thermistor_df[\"Absolute Time\"] = pd.to_datetime(\n",
    "    airflow_thermistor_df[\"Absolute Time\"], errors=\"coerce\"\n",
    ")\n",
    "df_plot = airflow_thermistor_df.iloc[-120000:-10000].copy()\n",
    "\n",
    "# keep valid rows and coerce numeric\n",
    "df_plot = df_plot.dropna(subset=[\"Absolute Time\", \"Flow Patient (Thermistor)\"]).copy()\n",
    "df_plot[\"Flow\"] = pd.to_numeric(df_plot[\"Flow Patient (Thermistor)\"], errors=\"coerce\")\n",
    "df_plot = df_plot.dropna(subset=[\"Flow\"])\n",
    "\n",
    "times  = df_plot[\"Absolute Time\"].to_numpy()\n",
    "signal = df_plot[\"Flow\"].to_numpy()\n",
    "\n",
    "# optional light detrend/standardize to help filtering/nk\n",
    "if len(signal):\n",
    "    signal = signal - np.nanmedian(signal)\n",
    "\n",
    "# ---------------- Bandpass filter (0.1â€“1.0 Hz) ----------------\n",
    "def bandpass(signal, fs, lo, hi, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    lo_n = max(lo / nyq, 1e-6)\n",
    "    hi_n = min(hi / nyq, 0.999999)\n",
    "    b, a = butter(order, [lo_n, hi_n], btype=\"bandpass\")\n",
    "    return filtfilt(b, a, signal, method=\"gust\")\n",
    "\n",
    "sig_filt = bandpass(signal, fs, bp_lo, bp_hi)\n",
    "\n",
    "# ---------------- Sliding-Window BPM on filtered signal ----------------\n",
    "samples_per_epoch = int(fs * epoch_len)\n",
    "step = samples_per_epoch  # no overlap\n",
    "n = len(sig_filt)\n",
    "\n",
    "bpm_times, bpm_values = [], []\n",
    "\n",
    "def bpm_welch(seg, fs, band=(0.10, 1.00)):\n",
    "    f, pxx = welch(seg, fs=fs, nperseg=min(len(seg), 2048))\n",
    "    low, high = band\n",
    "    mask = (f >= low) & (f <= high) & np.isfinite(pxx)\n",
    "    if np.any(mask) and np.nansum(pxx[mask]) > 0:\n",
    "        dom = f[mask][np.argmax(pxx[mask])]\n",
    "        return float(dom * 60.0)\n",
    "    return np.nan\n",
    "\n",
    "for start in range(0, n - samples_per_epoch + 1, step):\n",
    "    seg = sig_filt[start:start + samples_per_epoch]\n",
    "    if len(seg) < samples_per_epoch:\n",
    "        continue\n",
    "    seg_time = times[start + samples_per_epoch // 2]\n",
    "\n",
    "    bpm = np.nan\n",
    "    if HAVE_NK:\n",
    "        try:\n",
    "            # Use NeuroKit2 on the filtered segment\n",
    "            rr = nk.rsp_rate(seg, sampling_rate=fs, method=\"fft\")\n",
    "            if rr is not None and np.size(rr):\n",
    "                bpm = float(np.nanmedian(rr))\n",
    "            if not np.isfinite(bpm):\n",
    "                rr2 = nk.rsp_rate(seg, sampling_rate=fs, method=\"count\")\n",
    "                if rr2 is not None and np.size(rr2):\n",
    "                    bpm = float(np.nanmedian(rr2))\n",
    "        except Exception:\n",
    "            bpm = np.nan\n",
    "\n",
    "    if not np.isfinite(bpm):\n",
    "        bpm = bpm_welch(seg, fs, band=(bp_lo, bp_hi))\n",
    "\n",
    "    bpm_times.append(seg_time)\n",
    "    bpm_values.append(bpm)\n",
    "\n",
    "bpm_df = pd.DataFrame({\"Time\": bpm_times, \"BPM\": bpm_values})\n",
    "\n",
    "# ---------------- Plotly: raw + filtered + BPM ----------------\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1, shared_xaxes=True,\n",
    "    row_heights=[0.65, 0.35], vertical_spacing=0.08,\n",
    "    subplot_titles=(\n",
    "        f\"Airflow Thermistor (Raw vs. {bp_lo}-{bp_hi} Hz Bandpassed)\",\n",
    "        \"Estimated Breathing Rate (BPM, per 30s window)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Top: raw (thin) and filtered (thicker)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=times, y=signal, mode=\"lines\",\n",
    "               line=dict(width=1, color=\"rgba(30,144,255,0.6)\"),\n",
    "               name=\"Raw\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=times, y=sig_filt, mode=\"lines\",\n",
    "               line=dict(width=2, color=\"black\"),\n",
    "               name=f\"Filtered {bp_lo}-{bp_hi} Hz\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Bottom: BPM time series\n",
    "if len(bpm_df):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=bpm_df[\"Time\"], y=bpm_df[\"BPM\"],\n",
    "                   mode=\"lines+markers\",\n",
    "                   line=dict(width=2, color=\"crimson\"),\n",
    "                   name=\"BPM\"),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.add_hline(y=low_bpm_warn, line_dash=\"dot\", line_color=\"gray\", row=2, col=1)\n",
    "else:\n",
    "    fig.add_annotation(text=\"No BPM points (insufficient data / all-NaN).\",\n",
    "                       xref=\"paper\", yref=\"paper\", x=0.5, y=0.25,\n",
    "                       showarrow=False, font=dict(color=\"gray\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    height=700, width=1000,\n",
    "    legend=dict(orientation=\"h\", y=1.08, x=1, xanchor=\"right\")\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Flow (Thermistor)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Breaths/Minute\", row=2, col=1, range=[0, 40])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.signal import butter, filtfilt, welch, correlate\n",
    "import neurokit2 as nk\n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# ---- helper metrics ----\n",
    "def check_clipping(signal, digital_min=-100, digital_max=100, edge_pct=0.01):\n",
    "    if signal.size == 0:\n",
    "        return np.nan\n",
    "    lower, upper = digital_min * (1 - edge_pct), digital_max * (1 - edge_pct)\n",
    "    clipped = (signal <= lower) | (signal >= upper)\n",
    "    return float(np.mean(clipped))\n",
    "\n",
    "def flatline_ratio(signal, eps=1e-6):\n",
    "    if signal.size < 2:\n",
    "        return np.nan\n",
    "    diffs = np.abs(np.diff(signal, prepend=signal[:1]))\n",
    "    return float(np.mean(diffs < eps))\n",
    "\n",
    "def missing_ratio(n_present, n_expected):\n",
    "    if n_expected <= 0:\n",
    "        return np.nan\n",
    "    return float(max(0.0, 1.0 - n_present / n_expected))\n",
    "\n",
    "def bandpass_filter(sig, fs, lo=0.10, hi=1.00, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    lo_n, hi_n = max(lo / nyq, 1e-6), min(hi / nyq, 0.999999)\n",
    "    b, a = butter(order, [lo_n, hi_n], btype=\"bandpass\")\n",
    "    return filtfilt(b, a, sig, method=\"gust\")\n",
    "\n",
    "def bpm_welch(seg, fs, band=(0.10, 1.00)):\n",
    "    if seg.size == 0:\n",
    "        return np.nan\n",
    "    f, pxx = welch(seg, fs=fs, nperseg=min(len(seg), 2048))\n",
    "    m = (f >= band[0]) & (f <= band[1])\n",
    "    if np.any(m) and np.nansum(pxx[m]) > 0:\n",
    "        dom = f[m][np.argmax(pxx[m])]\n",
    "        return float(dom * 60.0)\n",
    "    return np.nan\n",
    "\n",
    "# ---- autocorrelation quality ----\n",
    "def autocorr_quality(seg, fs, max_lag_sec=10):\n",
    "    \"\"\"Compute normalized autocorrelation peak within lag window.\"\"\"\n",
    "    if len(seg) < fs:\n",
    "        return np.nan\n",
    "    seg = seg - np.nanmean(seg)\n",
    "    ac = correlate(seg, seg, mode='full')\n",
    "    ac = ac[len(ac)//2:]\n",
    "    if np.nanmax(np.abs(ac)) == 0:\n",
    "        return np.nan\n",
    "    ac /= np.nanmax(ac)\n",
    "    lags = np.arange(len(ac)) / fs\n",
    "    mask = (lags >= 1.0) & (lags <= max_lag_sec)\n",
    "    return float(np.nanmax(ac[mask])) if np.any(mask) else np.nan\n",
    "\n",
    "def ratio_summary(bad_n, total):\n",
    "    good_n = total - bad_n\n",
    "    return {\n",
    "        \"good_epochs\": int(good_n),\n",
    "        \"bad_epochs\": int(bad_n),\n",
    "        \"good_ratio\": round(good_n / total, 3) if total else None,\n",
    "        \"bad_ratio\": round(bad_n / total, 3) if total else None,\n",
    "    }\n",
    "\n",
    "# ---- main QC ----\n",
    "def run_flow_qc(\n",
    "    channel_name,\n",
    "    channel_dataframes,\n",
    "    fs=100,\n",
    "    epoch_len=30,\n",
    "    json_path=None,\n",
    "    plot=\"per-metric\",\n",
    "    clipping_max=0.50,\n",
    "    flatline_max=0.50,\n",
    "    missing_max=0.50,\n",
    "    bpm_min=10.0,\n",
    "    bpm_max=22.0,\n",
    "    auto_min=0.5   # ðŸ”¸ threshold for autocorrelation quality\n",
    "):\n",
    "    if channel_name not in channel_dataframes:\n",
    "        raise KeyError(f\"Channel '{channel_name}' not found.\")\n",
    "\n",
    "    df = channel_dataframes[channel_name]\n",
    "    t_abs = pd.to_datetime(df[\"Absolute Time\"], errors=\"coerce\")\n",
    "    if getattr(t_abs.dt, \"tz\", None) is None:\n",
    "        t_abs = t_abs.dt.tz_localize(\"UTC\")\n",
    "\n",
    "    t_abs_ns = t_abs.astype(\"int64\", copy=False)\n",
    "    sig_np = pd.to_numeric(df[channel_name], errors=\"coerce\").to_numpy(dtype=float)\n",
    "    mask = np.isfinite(sig_np) & np.isfinite(t_abs_ns)\n",
    "    sig, t_abs_ns = sig_np[mask].astype(np.float32), t_abs_ns[mask]\n",
    "\n",
    "    if sig.size == 0:\n",
    "        empty = {\n",
    "            \"total_epochs\": 0, \"good_epochs\": 0, \"bad_epochs\": 0,\n",
    "            \"good_ratio\": None, \"bad_ratio\": None\n",
    "        }\n",
    "        if json_path:\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump({\"per_epoch\": [], \"per_metric\": {}, \"overall\": empty}, f, indent=2)\n",
    "        return [], {}, empty\n",
    "\n",
    "    # --- prepare time base ---\n",
    "    t0_ns = t_abs_ns[0]\n",
    "    t_sec = (t_abs_ns - t0_ns) / 1e9\n",
    "    t0_dt = datetime.fromtimestamp(t0_ns / 1e9, tz=timezone.utc)\n",
    "\n",
    "    spp = int(fs * epoch_len)\n",
    "    starts = np.arange(0, len(sig), spp, dtype=int)\n",
    "    ends = np.minimum(starts + spp, len(sig))\n",
    "\n",
    "    per_epoch = []\n",
    "    for i, (s, e) in enumerate(zip(starts, ends), start=1):\n",
    "        seg = sig[s:e]\n",
    "        clip = check_clipping(seg)\n",
    "        flat = flatline_ratio(seg)\n",
    "        miss = missing_ratio(seg.size, spp)\n",
    "\n",
    "        try:\n",
    "            seg_filt = bandpass_filter(seg - np.nanmedian(seg), fs)\n",
    "        except Exception:\n",
    "            seg_filt = seg\n",
    "\n",
    "        bpm = np.nan\n",
    "        try:\n",
    "            rr = nk.rsp_rate(seg_filt, sampling_rate=fs, method=\"fft\")\n",
    "            if rr is not None and np.size(rr):\n",
    "                bpm = float(np.nanmedian(rr))\n",
    "            if not np.isfinite(bpm):\n",
    "                bpm2 = nk.rsp_rate(seg_filt, sampling_rate=fs, method=\"count\")\n",
    "                if bpm2 is not None and np.size(bpm2):\n",
    "                    bpm = float(np.nanmedian(bpm2))\n",
    "        except Exception:\n",
    "            pass\n",
    "        if not np.isfinite(bpm):\n",
    "            bpm = bpm_welch(seg_filt, fs)\n",
    "\n",
    "        # --- Autocorrelation ---\n",
    "        ac_score = autocorr_quality(seg_filt, fs)\n",
    "        bad_auto = bool(np.isfinite(ac_score) and ac_score < auto_min)\n",
    "\n",
    "        # --- QC flags ---\n",
    "        bad_clip = bool(np.isfinite(clip) and clip > clipping_max)\n",
    "        bad_flat = bool(np.isfinite(flat) and flat > flatline_max)\n",
    "        bad_miss = bool(np.isfinite(miss) and miss > missing_max)\n",
    "        bad_bpm_nan = bool(not np.isfinite(bpm))\n",
    "        bad_bpm_low = bool(np.isfinite(bpm) and bpm < bpm_min)\n",
    "        bad_bpm_high = bool(np.isfinite(bpm) and bpm > bpm_max)\n",
    "        bad_bpm = bool(bad_bpm_low or bad_bpm_high or bad_bpm_nan)\n",
    "        bad_epoch = bool(bad_clip or bad_flat or bad_miss or bad_bpm or bad_auto)\n",
    "\n",
    "        per_epoch.append({\n",
    "            \"Epoch\": int(i),\n",
    "            \"Start_Time_ISO\": (t0_dt + timedelta(seconds=float(t_sec[s]))).isoformat(),\n",
    "            \"End_Time_ISO\": (t0_dt + timedelta(seconds=float(t_sec[e - 1]))).isoformat(),\n",
    "            \"Clipping_Ratio\": float(clip) if np.isfinite(clip) else None,\n",
    "            \"Flatline_Ratio\": float(flat) if np.isfinite(flat) else None,\n",
    "            \"Missing_Ratio\": float(miss) if np.isfinite(miss) else None,\n",
    "            \"BPM\": float(bpm) if np.isfinite(bpm) else None,\n",
    "            \"AutoCorr_Q\": float(ac_score) if np.isfinite(ac_score) else None,\n",
    "            \"Bad_Epoch\": bad_epoch,\n",
    "            \"Bad_Clip\": bad_clip,\n",
    "            \"Bad_Flatline\": bad_flat,\n",
    "            \"Bad_Missing\": bad_miss,\n",
    "            \"Bad_BPM\": bad_bpm,\n",
    "            \"Bad_AutoCorr\": bad_auto,\n",
    "            \"Raw_Data\": seg.tolist()\n",
    "        })\n",
    "\n",
    "    # --- summaries ---\n",
    "    total = len(per_epoch)\n",
    "    def count(flag): return sum(1 for r in per_epoch if r[flag])\n",
    "    per_metric_json = {\n",
    "        \"Clipping\": ratio_summary(count(\"Bad_Clip\"), total),\n",
    "        \"Flatline\": ratio_summary(count(\"Bad_Flatline\"), total),\n",
    "        \"Missing\": ratio_summary(count(\"Bad_Missing\"), total),\n",
    "        \"BPM\": ratio_summary(count(\"Bad_BPM\"), total),\n",
    "        \"AutoCorr_Q\": ratio_summary(count(\"Bad_AutoCorr\"), total)\n",
    "    }\n",
    "    overall_bad = count(\"Bad_Epoch\")\n",
    "    overall_json = {\n",
    "        \"total_epochs\": total,\n",
    "        \"good_epochs\": total - overall_bad,\n",
    "        \"bad_epochs\": overall_bad,\n",
    "        \"good_ratio\": round((total - overall_bad) / total, 3) if total else None,\n",
    "        \"bad_ratio\": round(overall_bad / total, 3) if total else None,\n",
    "    }\n",
    "\n",
    "    # --- optional JSON save ---\n",
    "    if json_path:\n",
    "        with open(json_path, \"w\") as f:\n",
    "            json.dump(\n",
    "                {\"per_epoch\": per_epoch, \"per_metric\": per_metric_json, \"overall\": overall_json},\n",
    "                f, indent=2\n",
    "            )\n",
    "\n",
    "    # --- plotting ---\n",
    "    if plot in (\"overall\", \"per-metric\", \"both\"):\n",
    "        times = [t0_dt + timedelta(seconds=float(s)) for s in t_sec]\n",
    "\n",
    "        def shade(ax, flag_key):\n",
    "            for r in per_epoch:\n",
    "                st, et = datetime.fromisoformat(r[\"Start_Time_ISO\"]), datetime.fromisoformat(r[\"End_Time_ISO\"])\n",
    "                ax.axvspan(st, et, color=(\"red\" if r[flag_key] else \"green\"), alpha=0.18)\n",
    "\n",
    "        if plot in (\"overall\", \"both\"):\n",
    "            fig, ax = plt.subplots(figsize=(14, 5))\n",
    "            step = max(1, len(sig) // 20000)\n",
    "            ax.plot(times[::step], sig[::step], lw=0.8, color=\"black\")\n",
    "            shade(ax, \"Bad_Epoch\")\n",
    "            ax.set_title(f\"{channel_name} â€” Overall Flow QC (Red=Bad, Green=Good)\")\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "            ax.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "        if plot in (\"per-metric\", \"both\"):\n",
    "            flag_map = {\n",
    "                \"Clipping\": \"Bad_Clip\",\n",
    "                \"Flatline\": \"Bad_Flatline\",\n",
    "                \"Missing\": \"Bad_Missing\",\n",
    "                \"BPM\": \"Bad_BPM\",\n",
    "                \"AutoCorr_Q\": \"Bad_AutoCorr\"\n",
    "            }\n",
    "            for metric, flag in flag_map.items():\n",
    "                fig, ax = plt.subplots(figsize=(14, 5))\n",
    "                step = max(1, len(sig) // 20000)\n",
    "                ax.plot(times[::step], sig[::step], lw=0.8, color=\"black\")\n",
    "                shade(ax, flag)\n",
    "                ax.set_title(f\"{channel_name} â€” {metric} QC (Red=Bad, Green=Good)\")\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "                ax.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "    return per_epoch, per_metric_json, overall_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_epoch, per_metric_json, overall_json = run_flow_qc(\n",
    "    channel_name=\"Flow Patient (Thermistor)\",\n",
    "    channel_dataframes=channel_dataframes,\n",
    "    fs=100,\n",
    "    epoch_len=30,\n",
    "    json_path=False,          # or \"qc_results.json\" if you want to save to file\n",
    "    plot=\"per-metric\",        # options: \"overall\", \"per-metric\", \"both\", or 0 (none)\n",
    "    clipping_max=0.50,\n",
    "    flatline_max=0.50,\n",
    "    missing_max=0.50,\n",
    "    bpm_min=10.0,\n",
    "    bpm_max=22.0,\n",
    "    auto_min=0.5              # âœ… autocorrelation threshold (0â€“1 scale)\n",
    ")\n",
    "\n",
    "# Print overall QC summary\n",
    "print(json.dumps(overall_json, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save per_epoch to a separate JSON file ---\n",
    "with open(\"per_epoch_flow_temp.json\", \"w\") as f:\n",
    "    json.dump(per_epoch, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved per-epoch QC details to per_epoch.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# ---- Load the saved QC file ----\n",
    "json_path = \"per_epoch_flow_temp.json\"\n",
    "\n",
    "with open(json_path, \"r\") as f:\n",
    "    per_epoch = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(per_epoch)\n",
    "print(f\"âœ… Loaded {len(df)} epochs from {json_path}\")\n",
    "\n",
    "# ---- Convert times ----\n",
    "df[\"Start_Time_ISO\"] = pd.to_datetime(df[\"Start_Time_ISO\"], errors=\"coerce\")\n",
    "df[\"End_Time_ISO\"] = pd.to_datetime(df[\"End_Time_ISO\"], errors=\"coerce\")\n",
    "df[\"Mid_Time\"] = df[\"Start_Time_ISO\"] + (df[\"End_Time_ISO\"] - df[\"Start_Time_ISO\"]) / 2\n",
    "\n",
    "# ---- Define metrics and flags (AutoCorr_Q excluded from loop) ----\n",
    "metric_flags = {\n",
    "    \"Clipping_Ratio\": \"Bad_Clip\",\n",
    "    \"Flatline_Ratio\": \"Bad_Flatline\",\n",
    "    \"Missing_Ratio\": \"Bad_Missing\",\n",
    "    \"BPM\": \"Bad_BPM\",\n",
    "}\n",
    "\n",
    "available_metrics = [m for m in metric_flags if m in df.columns]\n",
    "print(f\"ðŸ“Š Available metrics for plotting: {available_metrics}\")\n",
    "\n",
    "# ---- Helper for shading ----\n",
    "def shade_epochs(ax, start_col, end_col, flag_col):\n",
    "    \"\"\"Shade epochs red (bad) or green (good).\"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[start_col]) or pd.isna(row[end_col]):\n",
    "            continue\n",
    "        color = \"red\" if row[flag_col] else \"green\"\n",
    "        ax.axvspan(row[start_col], row[end_col], color=color, alpha=0.18)\n",
    "\n",
    "# ---- Plot each QC metric ----\n",
    "for metric in available_metrics:\n",
    "    flag = metric_flags[metric]\n",
    "    if flag not in df.columns:\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(df[\"Mid_Time\"], df[metric], \"k.-\", label=metric)\n",
    "\n",
    "    # --- Add threshold lines ---\n",
    "    if metric == \"BPM\":\n",
    "        ax.axhline(10.0, color=\"gray\", linestyle=\"--\", lw=1, label=\"BPM Min (10)\")\n",
    "        ax.axhline(22.0, color=\"gray\", linestyle=\"--\", lw=1, label=\"BPM Max (22)\")\n",
    "\n",
    "    # --- Shading ---\n",
    "    shade_epochs(ax, \"Start_Time_ISO\", \"End_Time_ISO\", flag)\n",
    "\n",
    "    ax.set_title(f\"{metric} â€” Flow QC (Green = Good, Red = Bad)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---- Dedicated Autocorrelation Quality Plot ----\n",
    "if \"AutoCorr_Q\" in df.columns:\n",
    "    print(\"ðŸ“ˆ Plotting dedicated Autocorrelation Quality (AutoCorr_Q)...\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(df[\"Mid_Time\"], df[\"AutoCorr_Q\"], \"k.-\", label=\"AutoCorr_Q\")\n",
    "\n",
    "    # Add autocorrelation threshold line\n",
    "    ax.axhline(0.5, color=\"gray\", linestyle=\"--\", lw=1, label=\"AutoCorr Min (0.5)\")\n",
    "\n",
    "    shade_epochs(ax, \"Start_Time_ISO\", \"End_Time_ISO\", \"Bad_AutoCorr\")\n",
    "    ax.set_title(\"Autocorrelation Quality (AutoCorr_Q) â€” Flow QC (Green = Good, Red = Bad)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"AutoCorr_Q (0â€“1)\")\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Finished generating QC plots (AutoCorr_Q shown once).\")\n",
    "\n",
    "# ---- Combine all raw segments into one continuous trace ----\n",
    "if \"Raw_Data\" in df.columns:\n",
    "    print(\"ðŸ«€ Plotting raw waveform with QC shading...\")\n",
    "\n",
    "    # Concatenate all segments\n",
    "    raw_all = np.concatenate([\n",
    "        np.array(x, dtype=float) if isinstance(x, list) else np.array([])\n",
    "        for x in df[\"Raw_Data\"]\n",
    "    ])\n",
    "\n",
    "    # Approximate sampling rate and create time base\n",
    "    total_duration = (df[\"End_Time_ISO\"].iloc[-1] - df[\"Start_Time_ISO\"].iloc[0]).total_seconds()\n",
    "    fs = len(raw_all) / total_duration if total_duration > 0 else 100\n",
    "    t_start = df[\"Start_Time_ISO\"].iloc[0]\n",
    "    t_all = pd.date_range(start=t_start, periods=len(raw_all), freq=pd.Timedelta(seconds=1/fs))\n",
    "\n",
    "    print(f\"Reconstructed raw signal: {len(raw_all)} samples, fs â‰ˆ {fs:.2f} Hz\")\n",
    "\n",
    "    # ---- Plot raw waveform with shaded QC epochs ----\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.plot(t_all, raw_all, lw=0.7, color=\"black\")\n",
    "    shade_epochs(ax, \"Start_Time_ISO\", \"End_Time_ISO\", \"Bad_Epoch\")\n",
    "    ax.set_title(\"Flow Pressure Raw Signal â€” QC Overlay (Green = Good, Red = Bad)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ No 'Raw_Data' field found in JSON â€” skipping raw signal plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ FLOW Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airflow_pressure_df = channel_dataframes['Flow Patient (Pressure)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Parameters ----------------\n",
    "fs = 100                   # Hz\n",
    "epoch_len = 30             # seconds (non-overlapping)\n",
    "low_bpm_warn = 4.0         # draw a line at 4 BPM\n",
    "bp_lo, bp_hi = 0.10, 1.00  # Hz bandpass for airflow (resp band)\n",
    "\n",
    "# ---------------- Prepare Data ----------------\n",
    "airflow_pressure_df [\"Absolute Time\"] = pd.to_datetime(\n",
    "    airflow_pressure_df[\"Absolute Time\"], errors=\"coerce\"\n",
    ")\n",
    "df_plot = airflow_pressure_df.iloc[-120000:-10000].copy()\n",
    "\n",
    "# keep valid rows and coerce numeric\n",
    "df_plot = df_plot.dropna(subset=[\"Absolute Time\", \"Flow Patient (Pressure)\"]).copy()\n",
    "df_plot[\"Flow\"] = pd.to_numeric(df_plot[\"Flow Patient (Pressure)\"], errors=\"coerce\")\n",
    "df_plot = df_plot.dropna(subset=[\"Flow\"])\n",
    "\n",
    "times  = df_plot[\"Absolute Time\"].to_numpy()\n",
    "signal = df_plot[\"Flow\"].to_numpy()\n",
    "\n",
    "# optional light detrend/standardize to help filtering/nk\n",
    "if len(signal):\n",
    "    signal = signal - np.nanmedian(signal)\n",
    "\n",
    "# ---------------- Bandpass filter (0.1â€“1.0 Hz) ----------------\n",
    "def bandpass(signal, fs, lo, hi, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    lo_n = max(lo / nyq, 1e-6)\n",
    "    hi_n = min(hi / nyq, 0.999999)\n",
    "    b, a = butter(order, [lo_n, hi_n], btype=\"bandpass\")\n",
    "    return filtfilt(b, a, signal, method=\"gust\")\n",
    "\n",
    "sig_filt = bandpass(signal, fs, bp_lo, bp_hi)\n",
    "\n",
    "# ---------------- Sliding-Window BPM on filtered signal ----------------\n",
    "samples_per_epoch = int(fs * epoch_len)\n",
    "step = samples_per_epoch  # no overlap\n",
    "n = len(sig_filt)\n",
    "\n",
    "bpm_times, bpm_values = [], []\n",
    "\n",
    "def bpm_welch(seg, fs, band=(0.10, 1.00)):\n",
    "    f, pxx = welch(seg, fs=fs, nperseg=min(len(seg), 2048))\n",
    "    low, high = band\n",
    "    mask = (f >= low) & (f <= high) & np.isfinite(pxx)\n",
    "    if np.any(mask) and np.nansum(pxx[mask]) > 0:\n",
    "        dom = f[mask][np.argmax(pxx[mask])]\n",
    "        return float(dom * 60.0)\n",
    "    return np.nan\n",
    "\n",
    "for start in range(0, n - samples_per_epoch + 1, step):\n",
    "    seg = sig_filt[start:start + samples_per_epoch]\n",
    "    if len(seg) < samples_per_epoch:\n",
    "        continue\n",
    "    seg_time = times[start + samples_per_epoch // 2]\n",
    "\n",
    "    bpm = np.nan\n",
    "    if HAVE_NK:\n",
    "        try:\n",
    "            # Use NeuroKit2 on the filtered segment\n",
    "            rr = nk.rsp_rate(seg, sampling_rate=fs, method=\"fft\")\n",
    "            if rr is not None and np.size(rr):\n",
    "                bpm = float(np.nanmedian(rr))\n",
    "            if not np.isfinite(bpm):\n",
    "                rr2 = nk.rsp_rate(seg, sampling_rate=fs, method=\"count\")\n",
    "                if rr2 is not None and np.size(rr2):\n",
    "                    bpm = float(np.nanmedian(rr2))\n",
    "        except Exception:\n",
    "            bpm = np.nan\n",
    "\n",
    "    if not np.isfinite(bpm):\n",
    "        bpm = bpm_welch(seg, fs, band=(bp_lo, bp_hi))\n",
    "\n",
    "    bpm_times.append(seg_time)\n",
    "    bpm_values.append(bpm)\n",
    "\n",
    "bpm_df = pd.DataFrame({\"Time\": bpm_times, \"BPM\": bpm_values})\n",
    "\n",
    "# ---------------- Plotly: raw + filtered + BPM ----------------\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1, shared_xaxes=True,\n",
    "    row_heights=[0.65, 0.35], vertical_spacing=0.08,\n",
    "    subplot_titles=(\n",
    "        f\"Airflow Thermistor (Raw vs. {bp_lo}-{bp_hi} Hz Bandpassed)\",\n",
    "        \"Estimated Breathing Rate (BPM, per 30s window)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Top: raw (thin) and filtered (thicker)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=times, y=signal, mode=\"lines\",\n",
    "               line=dict(width=1, color=\"rgba(30,144,255,0.6)\"),\n",
    "               name=\"Raw\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=times, y=sig_filt, mode=\"lines\",\n",
    "               line=dict(width=2, color=\"black\"),\n",
    "               name=f\"Filtered {bp_lo}-{bp_hi} Hz\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Bottom: BPM time series\n",
    "if len(bpm_df):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=bpm_df[\"Time\"], y=bpm_df[\"BPM\"],\n",
    "                   mode=\"lines+markers\",\n",
    "                   line=dict(width=2, color=\"crimson\"),\n",
    "                   name=\"BPM\"),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.add_hline(y=low_bpm_warn, line_dash=\"dot\", line_color=\"gray\", row=2, col=1)\n",
    "else:\n",
    "    fig.add_annotation(text=\"No BPM points (insufficient data / all-NaN).\",\n",
    "                       xref=\"paper\", yref=\"paper\", x=0.5, y=0.25,\n",
    "                       showarrow=False, font=dict(color=\"gray\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    height=700, width=1000,\n",
    "    legend=dict(orientation=\"h\", y=1.08, x=1, xanchor=\"right\")\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Flow (Thermistor)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Breaths/Minute\", row=2, col=1, range=[0, 40])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt, welch, correlate\n",
    "from datetime import datetime\n",
    "import neurokit2 as nk\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ---------------- Parameters ----------------\n",
    "fs = 100                   # Sampling frequency (Hz)\n",
    "epoch_len = 30             # Window length (seconds)\n",
    "shift_sec = 5              # Shift between windows (seconds)\n",
    "low_bpm_warn = 4.0         # Threshold line for BPM\n",
    "bp_lo, bp_hi = 0.10, 1.00  # Bandpass limits for respiration (Hz)\n",
    "HAVE_NK = True             # NeuroKit availability\n",
    "\n",
    "# ---------------- Prepare Data ----------------\n",
    "airflow_pressure_df[\"Absolute Time\"] = pd.to_datetime(\n",
    "    airflow_pressure_df[\"Absolute Time\"], errors=\"coerce\"\n",
    ")\n",
    "df_plot = airflow_pressure_df.iloc[-200000:-10000].copy()\n",
    "df_plot = df_plot.dropna(subset=[\"Absolute Time\", \"Flow Patient (Pressure)\"]).copy()\n",
    "df_plot[\"Flow\"] = pd.to_numeric(df_plot[\"Flow Patient (Pressure)\"], errors=\"coerce\")\n",
    "df_plot = df_plot.dropna(subset=[\"Flow\"])\n",
    "\n",
    "times = df_plot[\"Absolute Time\"].to_numpy()\n",
    "signal = df_plot[\"Flow\"].to_numpy()\n",
    "if len(signal):\n",
    "    signal = signal - np.nanmedian(signal)\n",
    "\n",
    "# ---------------- Bandpass filter ----------------\n",
    "def bandpass(signal, fs, lo, hi, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    lo_n, hi_n = max(lo / nyq, 1e-6), min(hi / nyq, 0.999999)\n",
    "    b, a = butter(order, [lo_n, hi_n], btype=\"bandpass\")\n",
    "    return filtfilt(b, a, signal, method=\"gust\")\n",
    "\n",
    "sig_filt = bandpass(signal, fs, bp_lo, bp_hi)\n",
    "\n",
    "# ---------------- Autocorrelation Quality ----------------\n",
    "def autocorr_quality(seg, fs, max_lag_sec=10):\n",
    "    \"\"\"Compute normalized autocorrelation peak within a lag window.\"\"\"\n",
    "    if len(seg) < fs:\n",
    "        return np.nan\n",
    "    seg = seg - np.nanmean(seg)\n",
    "    ac = correlate(seg, seg, mode='full')\n",
    "    ac = ac[len(ac)//2:]  # keep positive lags\n",
    "    if np.nanmax(np.abs(ac)) == 0:\n",
    "        return np.nan\n",
    "    ac /= np.nanmax(ac)\n",
    "    lags = np.arange(len(ac)) / fs\n",
    "    mask = (lags >= 1.0) & (lags <= max_lag_sec)\n",
    "    return float(np.nanmax(ac[mask])) if np.any(mask) else np.nan\n",
    "\n",
    "# ---------------- BPM Estimation ----------------\n",
    "def bpm_welch(seg, fs, band=(0.10, 1.00)):\n",
    "    \"\"\"Estimate dominant frequency â†’ BPM using Welch PSD.\"\"\"\n",
    "    f, pxx = welch(seg, fs=fs, nperseg=min(len(seg), 2048))\n",
    "    mask = (f >= band[0]) & (f <= band[1])\n",
    "    if np.any(mask) and np.nansum(pxx[mask]) > 0:\n",
    "        dom = f[mask][np.argmax(pxx[mask])]\n",
    "        return float(dom * 60.0)\n",
    "    return np.nan\n",
    "\n",
    "# ---------------- Sliding Window Analysis ----------------\n",
    "samples_per_epoch = int(fs * epoch_len)\n",
    "step = int(fs * shift_sec)\n",
    "n = len(sig_filt)\n",
    "bpm_times, bpm_values, ac_scores = [], [], []\n",
    "\n",
    "for start in range(0, n - samples_per_epoch + 1, step):\n",
    "    seg = sig_filt[start:start + samples_per_epoch]\n",
    "    if len(seg) < samples_per_epoch:\n",
    "        continue\n",
    "    seg_time = times[start + samples_per_epoch // 2]\n",
    "\n",
    "    # --- Estimate Breathing Rate (BPM) ---\n",
    "    bpm = np.nan\n",
    "    if HAVE_NK:\n",
    "        try:\n",
    "            rr = nk.rsp_rate(seg, sampling_rate=fs, method=\"fft\")\n",
    "            if rr is not None and np.size(rr):\n",
    "                bpm = float(np.nanmedian(rr))\n",
    "            if not np.isfinite(bpm):\n",
    "                rr2 = nk.rsp_rate(seg, sampling_rate=fs, method=\"count\")\n",
    "                if rr2 is not None and np.size(rr2):\n",
    "                    bpm = float(np.nanmedian(rr2))\n",
    "        except Exception:\n",
    "            bpm = np.nan\n",
    "\n",
    "    if not np.isfinite(bpm):\n",
    "        bpm = bpm_welch(seg, fs)\n",
    "\n",
    "    # --- Autocorrelation Quality ---\n",
    "    ac_score = autocorr_quality(seg, fs)\n",
    "\n",
    "    bpm_times.append(seg_time)\n",
    "    bpm_values.append(bpm)\n",
    "    ac_scores.append(ac_score)\n",
    "\n",
    "bpm_df = pd.DataFrame({\n",
    "    \"Time\": bpm_times,\n",
    "    \"BPM\": bpm_values,\n",
    "    \"AutoCorr_Q\": ac_scores\n",
    "})\n",
    "\n",
    "# ---------------- Plotly Visualization ----------------\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1, shared_xaxes=True,\n",
    "    row_heights=[0.6, 0.25, 0.15],\n",
    "    vertical_spacing=0.07,\n",
    "    subplot_titles=(\n",
    "        f\"Airflow (Raw vs. {bp_lo}-{bp_hi} Hz Bandpassed)\",\n",
    "        f\"Estimated Breathing Rate (BPM, {epoch_len}s windows, {shift_sec}s shift)\",\n",
    "        \"Autocorrelation-Based Signal Quality\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Top: raw + filtered\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=times, y=signal, mode=\"lines\",\n",
    "    line=dict(width=1, color=\"rgba(30,144,255,0.6)\"),\n",
    "    name=\"Raw\"), 1, 1)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=times, y=sig_filt, mode=\"lines\",\n",
    "    line=dict(width=2, color=\"black\"),\n",
    "    name=f\"Filtered {bp_lo}-{bp_hi} Hz\"), 1, 1)\n",
    "\n",
    "# BPM\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=bpm_df[\"Time\"], y=bpm_df[\"BPM\"],\n",
    "    mode=\"lines+markers\",\n",
    "    line=dict(width=2, color=\"crimson\"),\n",
    "    name=\"BPM\"), 2, 1)\n",
    "fig.add_hline(y=low_bpm_warn, line_dash=\"dot\", line_color=\"gray\", row=2, col=1)\n",
    "\n",
    "# Autocorr quality\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=bpm_df[\"Time\"], y=bpm_df[\"AutoCorr_Q\"],\n",
    "    mode=\"lines+markers\",\n",
    "    line=dict(width=2, color=\"orange\"),\n",
    "    name=\"AutoCorr_Q\"), 3, 1)\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    height=900, width=1100,\n",
    "    legend=dict(orientation=\"h\", y=1.12, x=1, xanchor=\"right\")\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Time\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Flow\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"BPM\", range=[0, 40], row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Autocorr (0â€“1)\", range=[0, 1], row=3, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt, welch, correlate\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ---------------- Parameters ----------------\n",
    "fs = 100               # Hz\n",
    "duration = 300         # 5 minutes\n",
    "t = np.arange(0, duration, 1/fs)\n",
    "freq_base = 0.2        # 12 BPM = 0.2 Hz base respiration\n",
    "rng = np.random.default_rng(42)  # reproducibility\n",
    "\n",
    "# ---------------- Base Clean Signal ----------------\n",
    "signal_clean = np.sin(2 * np.pi * freq_base * t)\n",
    "signal_noisy = signal_clean.copy()\n",
    "\n",
    "# ---------------- Noise Section Definitions ----------------\n",
    "# 0â€“60 s: low drift + light Gaussian noise\n",
    "drift1 = 0.15 * np.sin(2 * np.pi * 0.02 * t[:fs*60])\n",
    "signal_noisy[:fs*60] += drift1 + 0.03 * rng.standard_normal(fs*60)\n",
    "\n",
    "# 60â€“120 s: in-band irregular breathing (0.3 Hz and 0.5 Hz modulation)\n",
    "mix1 = (0.15 * np.sin(2 * np.pi * 0.3 * t[fs*60:fs*120]) +\n",
    "        0.08 * np.sin(2 * np.pi * 0.5 * t[fs*60:fs*120]))\n",
    "signal_noisy[fs*60:fs*120] += mix1 + 0.05 * rng.standard_normal(fs*60)\n",
    "\n",
    "# 120â€“180 s: stronger in-band + motion noise (0.7â€“1 Hz)\n",
    "mix2 = (0.20 * np.sin(2 * np.pi * 0.7 * t[fs*120:fs*180]) +\n",
    "        0.12 * np.sin(2 * np.pi * 1.0 * t[fs*120:fs*180]))\n",
    "signal_noisy[fs*120:fs*180] += mix2 + 0.08 * rng.standard_normal(fs*60)\n",
    "\n",
    "# 180â€“210 s: high-frequency jitter (3â€“5 Hz)\n",
    "hf1 = 0.08 * np.sin(2 * np.pi * 4.0 * t[fs*180:fs*210]) + 0.05 * rng.standard_normal(fs*30)\n",
    "signal_noisy[fs*180:fs*210] += hf1\n",
    "\n",
    "# 210â€“240 s: mixed HF jitter + low-frequency drift (combined artifacts)\n",
    "hf2 = 0.06 * np.sin(2 * np.pi * 3.5 * t[fs*210:fs*240])\n",
    "drift2 = 0.10 * np.sin(2 * np.pi * 0.05 * t[fs*210:fs*240])\n",
    "signal_noisy[fs*210:fs*240] += hf2 + drift2 + 0.07 * rng.standard_normal(fs*30)\n",
    "\n",
    "# 240â€“260 s: flatline (sensor dropout)\n",
    "signal_noisy[fs*240:fs*260] = 0.0\n",
    "\n",
    "# 260â€“300 s: recovery â€” mild drift + small in-band wobble + light noise\n",
    "drift3 = 0.08 * np.sin(2 * np.pi * 0.04 * t[fs*260:])\n",
    "rebound = 0.05 * np.sin(2 * np.pi * 0.25 * t[fs*260:])\n",
    "signal_noisy[fs*260:] += drift3 + rebound + 0.02 * rng.standard_normal(len(t) - fs*260)\n",
    "\n",
    "# ---------------- Bandpass Filter (0.1â€“1 Hz) ----------------\n",
    "def bandpass(sig, fs, lo=0.1, hi=1.0, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [lo/nyq, hi/nyq], btype=\"bandpass\")\n",
    "    return filtfilt(b, a, sig, method=\"gust\")\n",
    "\n",
    "sig_filt = bandpass(signal_noisy, fs)\n",
    "\n",
    "# ---------------- Autocorrelation Quality ----------------\n",
    "def autocorr_quality(seg, fs, max_lag_sec=10):\n",
    "    if len(seg) < fs:\n",
    "        return np.nan\n",
    "    seg = seg - np.nanmean(seg)\n",
    "    ac = correlate(seg, seg, mode=\"full\")[len(seg)-1:]\n",
    "    ac /= np.nanmax(np.abs(ac)) if np.nanmax(np.abs(ac)) != 0 else 1\n",
    "    lags = np.arange(len(ac)) / fs\n",
    "    mask = (lags >= 1.0) & (lags <= max_lag_sec)\n",
    "    return float(np.nanmax(ac[mask])) if np.any(mask) else np.nan\n",
    "\n",
    "# ---------------- BPM Estimation ----------------\n",
    "def bpm_welch(seg, fs, band=(0.1, 1.0)):\n",
    "    f, pxx = welch(seg, fs=fs, nperseg=min(len(seg), 2048))\n",
    "    m = (f >= band[0]) & (f <= band[1])\n",
    "    if np.any(m) and np.nansum(pxx[m]) > 0:\n",
    "        return float(f[m][np.argmax(pxx[m])] * 60.0)\n",
    "    return np.nan\n",
    "\n",
    "# ---------------- Sliding Windows (30 s, shift 5 s) ----------------\n",
    "epoch_len, shift_sec = 30, 5\n",
    "samples_per_epoch = int(fs * epoch_len)\n",
    "step = int(fs * shift_sec)\n",
    "n = len(sig_filt)\n",
    "\n",
    "bpm_times, bpm_values, ac_scores = [], [], []\n",
    "times = pd.date_range(\"2022-01-01\", periods=len(t), freq=f\"{1000/fs}ms\")\n",
    "\n",
    "for start in range(0, n - samples_per_epoch + 1, step):\n",
    "    seg = sig_filt[start:start+samples_per_epoch]\n",
    "    seg_time = times[start + samples_per_epoch//2]\n",
    "    bpm = bpm_welch(seg, fs)\n",
    "    ac = autocorr_quality(seg, fs)\n",
    "    bpm_times.append(seg_time)\n",
    "    bpm_values.append(bpm)\n",
    "    ac_scores.append(ac)\n",
    "\n",
    "bpm_df = pd.DataFrame({\"Time\": bpm_times, \"BPM\": bpm_values, \"AutoCorr_Q\": ac_scores})\n",
    "\n",
    "# ---------------- Visualization ----------------\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1, shared_xaxes=True,\n",
    "    row_heights=[0.55, 0.25, 0.2], vertical_spacing=0.06,\n",
    "    subplot_titles=(\n",
    "        \"Synthetic Respiration (12 BPM Base, Multi-Zone Noise & Dropout)\",\n",
    "        \"Estimated Breathing Rate (BPM)\",\n",
    "        \"Autocorrelation-Based Signal Quality\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=times, y=signal_noisy, mode=\"lines\",\n",
    "                         line=dict(width=1, color=\"rgba(30,144,255,0.6)\"),\n",
    "                         name=\"Raw (variable noise)\"), 1, 1)\n",
    "fig.add_trace(go.Scatter(x=times, y=sig_filt, mode=\"lines\",\n",
    "                         line=dict(width=2, color=\"black\"),\n",
    "                         name=\"Filtered 0.1â€“1 Hz\"), 1, 1)\n",
    "fig.add_trace(go.Scatter(x=bpm_df[\"Time\"], y=bpm_df[\"BPM\"],\n",
    "                         mode=\"lines+markers\",\n",
    "                         line=dict(width=2, color=\"crimson\"),\n",
    "                         name=\"BPM (Welch)\"), 2, 1)\n",
    "fig.add_hline(y=12, line_dash=\"dot\", line_color=\"gray\", row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=bpm_df[\"Time\"], y=bpm_df[\"AutoCorr_Q\"],\n",
    "                         mode=\"lines+markers\",\n",
    "                         line=dict(width=2, color=\"orange\"),\n",
    "                         name=\"Autocorr Q\"), 3, 1)\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\", height=950, width=1150,\n",
    "    legend=dict(orientation=\"h\", y=1.1, x=1, xanchor=\"right\")\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Time\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Flow\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"BPM\", range=[0, 25], row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Autocorr (0â€“1)\", range=[0, 1], row=3, col=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_epoch, per_metric_json, overall_json = run_flow_qc(\n",
    "    channel_name=\"Flow Patient (Pressure)\",\n",
    "    channel_dataframes=channel_dataframes,\n",
    "    fs=100,\n",
    "    epoch_len=30,\n",
    "    json_path=False,          # or \"qc_results.json\" if you want to save to file\n",
    "    plot=\"per-metric\",        # options: \"overall\", \"per-metric\", \"both\", or 0 (none)\n",
    "    clipping_max=0.50,\n",
    "    flatline_max=0.50,\n",
    "    missing_max=0.50,\n",
    "    bpm_min=10.0,\n",
    "    bpm_max=22.0,\n",
    "    auto_min=0.5              # âœ… autocorrelation threshold (0â€“1 scale)\n",
    ")\n",
    "\n",
    "# Print overall QC summary\n",
    "print(json.dumps(overall_json, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# --- Save per_epoch to a separate JSON file ---\n",
    "with open(\"per_epoch_flow_pressure.json\", \"w\") as f:\n",
    "    json.dump(per_epoch, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved per-epoch QC details to per_epoch.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# ---- Load the saved QC file ----\n",
    "json_path = \"per_epoch_flow_pressure.json\"\n",
    "\n",
    "with open(json_path, \"r\") as f:\n",
    "    per_epoch = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(per_epoch)\n",
    "print(f\"âœ… Loaded {len(df)} epochs from {json_path}\")\n",
    "\n",
    "# ---- Convert times ----\n",
    "df[\"Start_Time_ISO\"] = pd.to_datetime(df[\"Start_Time_ISO\"], errors=\"coerce\")\n",
    "df[\"End_Time_ISO\"] = pd.to_datetime(df[\"End_Time_ISO\"], errors=\"coerce\")\n",
    "df[\"Mid_Time\"] = df[\"Start_Time_ISO\"] + (df[\"End_Time_ISO\"] - df[\"Start_Time_ISO\"]) / 2\n",
    "\n",
    "# ---- Define metrics and flags (AutoCorr_Q excluded from loop) ----\n",
    "metric_flags = {\n",
    "    \"Clipping_Ratio\": \"Bad_Clip\",\n",
    "    \"Flatline_Ratio\": \"Bad_Flatline\",\n",
    "    \"Missing_Ratio\": \"Bad_Missing\",\n",
    "    \"BPM\": \"Bad_BPM\",\n",
    "}\n",
    "\n",
    "available_metrics = [m for m in metric_flags if m in df.columns]\n",
    "print(f\"ðŸ“Š Available metrics for plotting: {available_metrics}\")\n",
    "\n",
    "# ---- Helper for shading ----\n",
    "def shade_epochs(ax, start_col, end_col, flag_col):\n",
    "    \"\"\"Shade epochs red (bad) or green (good).\"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[start_col]) or pd.isna(row[end_col]):\n",
    "            continue\n",
    "        color = \"red\" if row[flag_col] else \"green\"\n",
    "        ax.axvspan(row[start_col], row[end_col], color=color, alpha=0.18)\n",
    "\n",
    "# ---- Plot each QC metric ----\n",
    "for metric in available_metrics:\n",
    "    flag = metric_flags[metric]\n",
    "    if flag not in df.columns:\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(df[\"Mid_Time\"], df[metric], \"k.-\", label=metric)\n",
    "\n",
    "    # --- Add threshold lines ---\n",
    "    if metric == \"BPM\":\n",
    "        ax.axhline(10.0, color=\"gray\", linestyle=\"--\", lw=1, label=\"BPM Min (10)\")\n",
    "        ax.axhline(22.0, color=\"gray\", linestyle=\"--\", lw=1, label=\"BPM Max (22)\")\n",
    "\n",
    "    # --- Shading ---\n",
    "    shade_epochs(ax, \"Start_Time_ISO\", \"End_Time_ISO\", flag)\n",
    "\n",
    "    ax.set_title(f\"{metric} â€” Flow QC (Green = Good, Red = Bad)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---- Dedicated Autocorrelation Quality Plot ----\n",
    "if \"AutoCorr_Q\" in df.columns:\n",
    "    print(\"ðŸ“ˆ Plotting dedicated Autocorrelation Quality (AutoCorr_Q)...\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(df[\"Mid_Time\"], df[\"AutoCorr_Q\"], \"k.-\", label=\"AutoCorr_Q\")\n",
    "\n",
    "    # Add autocorrelation threshold line\n",
    "    ax.axhline(0.5, color=\"gray\", linestyle=\"--\", lw=1, label=\"AutoCorr Min (0.5)\")\n",
    "\n",
    "    shade_epochs(ax, \"Start_Time_ISO\", \"End_Time_ISO\", \"Bad_AutoCorr\")\n",
    "    ax.set_title(\"Autocorrelation Quality (AutoCorr_Q) â€” Flow QC (Green = Good, Red = Bad)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"AutoCorr_Q (0â€“1)\")\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Finished generating QC plots (AutoCorr_Q shown once).\")\n",
    "\n",
    "# ---- Combine all raw segments into one continuous trace ----\n",
    "if \"Raw_Data\" in df.columns:\n",
    "    print(\"ðŸ«€ Plotting raw waveform with QC shading...\")\n",
    "\n",
    "    # Concatenate all segments\n",
    "    raw_all = np.concatenate([\n",
    "        np.array(x, dtype=float) if isinstance(x, list) else np.array([])\n",
    "        for x in df[\"Raw_Data\"]\n",
    "    ])\n",
    "\n",
    "    # Approximate sampling rate and create time base\n",
    "    total_duration = (df[\"End_Time_ISO\"].iloc[-1] - df[\"Start_Time_ISO\"].iloc[0]).total_seconds()\n",
    "    fs = len(raw_all) / total_duration if total_duration > 0 else 100\n",
    "    t_start = df[\"Start_Time_ISO\"].iloc[0]\n",
    "    t_all = pd.date_range(start=t_start, periods=len(raw_all), freq=pd.Timedelta(seconds=1/fs))\n",
    "\n",
    "    print(f\"Reconstructed raw signal: {len(raw_all)} samples, fs â‰ˆ {fs:.2f} Hz\")\n",
    "\n",
    "    # ---- Plot raw waveform with shaded QC epochs ----\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.plot(t_all, raw_all, lw=0.7, color=\"black\")\n",
    "    shade_epochs(ax, \"Start_Time_ISO\", \"End_Time_ISO\", \"Bad_Epoch\")\n",
    "    ax.set_title(\"Flow Pressure Raw Signal â€” QC Overlay (Green = Good, Red = Bad)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ No 'Raw_Data' field found in JSON â€” skipping raw signal plot.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
